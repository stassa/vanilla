Poker: Self-supervised learning of recursive logic programs with invented predicates  
====================================================================================

This README file is a work in progress, to be updated with examples of use in
good time. Meanwhile, more information can be found in the following pre-print
of a paper introducing Poker and the new Self-Supervised ILP setting in which
Poker operates: 

[Self-Supervised Inductive Logic Programming](https://arxiv.org/abs/2507.16405). 


Introduction
------------

Poker is a self-supervised Meta-Interpretive Learning (MIL) system based on
[Louise](https://github.com/stassa/vanilla/tree/master/lib/louise) and its Top
Program Construction algorithm.

Poker is "self-supervised" in the sense that it can automatically generate new
positive and negative examples during learning, and label them consistently with
positive examples. This way Poker can learn from one or more labelled,
positive-only examples and zero or more unlabelled examples. The ability to
automatically generate new negative examples obviates the need for labelled
negative examples.

Poker's higher-order background theory is a Second-Order Normal Form,
abbreviated SONF (for ease of pronounciation). SONFs are sets of second-order
definite clauses (unfortunately called "metarules", in the MIL literature)
sufficiently general to learn all programs in a class, and so removing the need
for problem-specific background theories, common in MIL and other Inductive
Logic Programming (ILP) approaches.

SONFs impose constraints on the substitutions of second-order variables in
"metarules", chosen so as to reduce unnecessary recursion and other redundancy,
and thereby improve efficiency while learning programs with many literals with
recursion and invented predicates. Thus, SONFs perform much the same function as
heuristics exploiting the common structure of problems in a domain, as e.g. used
in SAT-solving or Planning and Scheduling.

Poker labels unlabelled examples during learning (both the ones given by a user,
and the ones generated automatically). At the end of learning, Poker returns
both a learned hypothesis and the labelling of unlabelled examples used to learn
the hypothesis. Learned labellings are particularly useful when trying to debug
and tweak Poker's configuration to maximise its accuracy.

Poker is named not after the card game but after [Wittgenstein's
Poker](https://en.wikipedia.org/wiki/Wittgenstein%27s_Poker); a friendly dig at
[Popper](https://github.com/logic-and-learning-lab/Popper/).


Examples of use
---------------

See the [vanilla/data/poker_examples](../../data/poker_examples) directory for
examples of scripts setting up experiments with Poker.

See
[vanilla/data/poker_examples/hello_world.pl](../../data/poker_examples/hello_world_poker.pl)
for a simple example of using Poker to learn an ancestor relation with recursion
but no predicate invention.

The following is a short example of the output of a learning session with Poker,
learning a grammar of the Hilbert Curve L-System language, in Definite Clause
Grammars (DCG) form. In this experiment, labelled and unlabelled training
examples are generated by a ground truth Hilbert Curve grammar defined in
[data/poker_examples/l_systems](../../data/poker_examples/l_systems.pl):

```prolog
?- experiment_file:hilbert_curve.

Current table space 2,147,483,648
New table space 4,294,967,296
% Generating labelled examples...
% Generating all hilbert_curve examples of length in [0,4].
% Generating all hilbert_curve_with_vars examples of length in [11,11].
% Generating unlabelled examples...
% Got 123 labelled examples.
% Got 0 unlabelled examples.
% Generalising positive examples
% Derived 2709 sub-hypotheses (unsorted)
% Derived 89 sub-hypotheses (sorted)
% Derived 47 sub-hypotheses (unfolded)
% Generating new atoms...
% Found safe_example/2.
% Generated 0 new atoms.
% Wall Clock time: 71.4175 CPU time: 30.6250 Inferences: 301,133,456
% Learned 6 clause hypothesis.
% Learned hypothesis:
% s(A,B,C):-y(B,D),minus(A,E),x(E,F),f(F,G),plus(G,H),y(H,I),f(I,J),y(J,K),plus(K,L),f(L,M),x(M,N),minus(N,O),s(O,D,C)
% s(A,B,C):-x(B,D),plus(A,E),y(E,F),f(F,G),minus(G,H),x(H,I),f(I,J),x(J,K),minus(K,L),f(L,M),y(M,N),plus(N,O),s(O,D,C)
% s(A,B,C):-plus(B,D),plus(A,E),s(E,D,C)
% s(A,B,C):-minus(B,D),minus(A,E),s(E,D,C)
% s(A,B,C):-f(B,D),f(A,E),s(E,D,C)
% s(A,B,B):-empty(A,B)
% Labelled 123 Positive examples.
% Labelled 0 Negative examples.
% Testing labelling for target: hilbert_curve
% Labelling: Measured Acc: 1.0 TPR: 1.0 TNR: 0.0
% Testing learned program for target: hilbert_curve
% Generating 10000 hilbert_curve examples of length in [0,12].
% Generated 10000 positive testing examples
% Generating 10000 not_hilbert_curve examples of length in [0,4].
% Generated 10000 negative testing examples
% Program: Measured Acc: 1.0 TPR: 1.0 TNR: 1.0
Learned Hypothesis:
s(A,B,C):-y(B,D),minus(A,E),x(E,F),f(F,G),plus(G,H),y(H,I),f(I,J),y(J,K),plus(K,L),f(L,M),x(M,N),minus(N,O),s(O,D,C).
s(A,B,C):-x(B,D),plus(A,E),y(E,F),f(F,G),minus(G,H),x(H,I),f(I,J),x(J,K),minus(K,L),f(L,M),y(M,N),plus(N,O),s(O,D,C).
s(A,B,C):-plus(B,D),plus(A,E),s(E,D,C).
s(A,B,C):-minus(B,D),minus(A,E),s(E,D,C).
s(A,B,C):-f(B,D),f(A,E),s(E,D,C).
s(A,B,B):-empty(A,B).
Program Length: 6
Labelled Positive: 123
Labelled Negative: 0

Labelling Results:
         Predicted + Predicted - Total
Actual + 123         0           123
Actual - 0           0           0
-------------------------------------
Total    123         0           123
Accuracy:            1.0000
Error:               0.0000
True Positive Rate:  1.0000
True Negative Rate:  0.0000
False Positive Rate: 1.0000
False Negative Rate: 0.0000
Precision:           1.0000
Recall (TPR):        1.0000
F-Score:             1.0000

Hypothesis Results:
         Predicted + Predicted - Total
Actual + 10000       0           10000
Actual - 0           10000       10000
-------------------------------------
Total    10000       10000       123
Accuracy:            1.0000
Error:               0.0000
True Positive Rate:  1.0000
True Negative Rate:  1.0000
False Positive Rate: 0.0000
False Negative Rate: 0.0000
Precision:           1.0000
Recall (TPR):        1.0000
F-Score:             1.0000
Generative Acc: 0.0
Current table space 4,294,967,296
New table space 2,147,483,648
true.
```

See
[vanilla/data/poker_examples/experiment_script_lnf.pl](../../data/poker_examples/experiment_script_lnf.pl)
for more experiments learning L-System DCGs, including experiments drawing
learned L-Systems with a Turtle language interpreter.

See
[vanilla/data/poker_examples/experiment_script_binary_cgnf.pl](../../data/poker_examples/experiment_script_binary_cgnf.pl)
for experiments learning DCGs for Context-Free Languages.
